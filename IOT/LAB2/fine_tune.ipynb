{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3971b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (until.py, line 39)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92md:\\PTIT\\NAM_4\\IOT\\LAB2\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3699\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[36m  \u001b[39m\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mimport until\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32md:\\PTIT\\NAM_4\\IOT\\LAB2\\until.py:39\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mtime svm.fit(train_features, y_train.ravel())\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import until\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo thư mục lưu dữ liệu\n",
    "class_names = ['with_mask', 'without_mask', 'incorrect_mask']\n",
    "svm_model = until.load_svm_model()\n",
    "resnet50_fe_model = until.load_resnet50_fe_model()\n",
    "yolo_model = until.load_yolo_model()\n",
    "\n",
    "# Dataset\n",
    "labels = []\n",
    "images = []\n",
    "\n",
    "# Cấu hình webcam và tham số\n",
    "cap = cv2.VideoCapture(0)\n",
    "frames_per_label = 30\n",
    "capture_time = 5  # giây\n",
    "wait_time = 5     # giây giữa các nhãn\n",
    "\n",
    "for idx, label in enumerate(class_names):\n",
    "    print(f\"Chuẩn bị lấy ảnh cho nhãn: {label}. Đợi {wait_time} giây...\")\n",
    "    time.sleep(wait_time)\n",
    "    print(f\"Bắt đầu lấy ảnh cho nhãn: {label}\")\n",
    "    count = 0\n",
    "    start = time.time()\n",
    "    while count < frames_per_label and (time.time() - start) < capture_time:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        face, bbox = until.crop_face(frame, yolo_model)\n",
    "        if face is None:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        face_resized = cv2.resize(face, (224, 224))\n",
    "        face_resized = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)\n",
    "        face_resized = np.array(face_resized)\n",
    "        labels.append(label)\n",
    "        images.append(face_resized)\n",
    "        count += 1\n",
    "        cv2.imshow('Frame', face_resized)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    print(f\"Đã lấy xong {count} ảnh cho nhãn: {label}\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Số ảnh train: {len(X_train)}, Số ảnh val: {len(X_val)}\")\n",
    "print(f\"Phân bố nhãn train: {np.unique(y_train, return_counts=True)}\")\n",
    "print(f\"Phân bố nhãn val: {np.unique(y_val, return_counts=True)}\")\n",
    "print(f\"Ảnh train: {X_train[0].shape}, Ảnh val: {X_val[0].shape}\")\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    print(f\"Ảnh train {i}: {y_train[i]}\")\n",
    "    cv2.imshow(f\"{y_train[i]}\", X_train[i])\n",
    "    cv2.waitKey(500)  # hiển thị 0.5s mỗi ảnh\n",
    "\n",
    "for i in range(len(X_val)):\n",
    "    print(f\"Ảnh val {i} label {y_val[i]}: {y_val[i]}\")\n",
    "    cv2.imshow(f\"{y_val[i]}\", X_val[i])\n",
    "    cv2.waitKey(100)  # hiển thị 0.3s mỗi ảnh\n",
    "\n",
    "print(\"Bắt đầu fine-tune ResNet50...\")\n",
    "print(\"Press any key to continue...\")\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d29bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data augmentation ---\n",
    "print(\"Data augmentation...\")\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_resnet50_finetuned.h5', save_best_only=True)\n",
    "lr_plat = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6)\n",
    "\n",
    "# Fine-tune \n",
    "print(\"Fine-tuning ResNet50...\")\n",
    "finetune_resneted, history = until.finetune_resnet50(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_val,\n",
    "    y_test=y_val,\n",
    "    model=resnet50_fe_model,\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping, model_checkpoint, lr_plat],\n",
    "    verbose=1)\n",
    "\n",
    "finetune_resneted.save('resnet50_finetuned.h5')\n",
    "print(\"Đã fine-tune xong và lưu model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
